{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Starter_code_Assignment_CNN_Skin_Cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "# Problem statement\n",
        "To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpUsRQwOOL72"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTHkTvKsHZ8W"
      },
      "source": [
        "## Building a simple CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvR7ppk77v31"
      },
      "source": [
        "#### **Task 1: Reading the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "Importing all the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "source": [
        "# Importing the required libraries\n",
        "import pathlib\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8BKCg1aEzqy"
      },
      "source": [
        "You are expected to load the data in the Colab environment by mounting the Google Drive. This will allow you to access the files from Google drive through Colab. \n",
        "\n",
        "Steps:\n",
        "1. Upload the dataset in your Google Drive in a separate folder. Avoid spaces in the name of the folder or the zip file.\n",
        "2. Mount the Google Drive using the code given below.\n",
        "3. Unzip the file to access images.\n",
        "4. Check the path for the datasets - train and test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9qFntWNOKB1"
      },
      "source": [
        "Note: The code is commented for you to learn and then make edits to execute the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpVPmT5z7AP"
      },
      "source": [
        "## If you are using the data by mounting the google drive, use the following:\n",
        "## from google.colab import drive\n",
        "## drive.mount('/content/gdrive')\n",
        "\n",
        "## Ref:https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD4mPiCSOfxK"
      },
      "source": [
        "# Your GDrive Directory\n",
        "!ls /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUw-lQfRMPh4"
      },
      "source": [
        "# Unzipping the files\n",
        "# To do: Update the folder name and file name\n",
        "!unzip /content/gdrive/My\\ Drive/folder_name/zip_file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mNDUchCGxCB"
      },
      "source": [
        "Check the path mentioned in the output: `Skin cancer ISIC The International Skin Imaging Collaboration`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS0fZ7d8G1Tn"
      },
      "source": [
        "Provide the path for train and test images using pathlib library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "source": [
        "# Defining the path for train and test images\n",
        "## To do: Update the paths of the train and test dataset\n",
        "data_dir_train = pathlib.Path(\"path_to_train_directory\")\n",
        "data_dir_test = pathlib.Path('path_to_test_directory')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGoopgogP-aD"
      },
      "source": [
        "Check whether the data has been extracted successfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqksN1w5Fu-N"
      },
      "source": [
        "# Train and test images\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(\"Train images:\\t\", image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(\"Test images:\\t\", image_count_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8HkfW3jPJun"
      },
      "source": [
        "#### **Task 2: Loading the images using keras.preprocessing**\n",
        "\n",
        "The images are still not loaded in the Colab environment. We have extracted them from the zip file. Now, you are expected to load them in the Colab notebook using the `preprocessing` attribute.\n",
        "\n",
        "Let's load these images off disk using the helpful image_dataset_from_directory utility. You can refer to the following [link](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) to know more about the function. You can even refer to the additional notebooks on the page to check how the variables are defined.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "Defining the parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Divide the training set into 2 parts: \n",
        "*   80% for training \n",
        "*   20% for validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "source": [
        "## Write your code for train dataset here.\n",
        "## Note: Use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note: Make sure you resize your images to the size: img_height*img_width, while specifying the variable\n",
        "\n",
        "train_ds = ##Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "source": [
        "## Write your code for validation dataset here.\n",
        "## Note: Use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note: Make sure you resize your images to the size: img_height*img_width, while specifying the variable\n",
        "\n",
        "val_ds = ##Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "source": [
        "# List out all the classes of skin cancer and store them in a list. \n",
        "# You can find the class names in the 'class_names' attribute associated with the training and validation datasets. \n",
        "# These correspond to the directory names in alphabetical order.\n",
        "\n",
        "class_names = ## Write your code here\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "#### **Task 3: Visualize the data**\n",
        "\n",
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.\n",
        "\n",
        "Write the code to visualize one instance of all the nine classes present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKILZ48I-q1k"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Your code goes here; you can use either training or validation data to visualize the images."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH05xqE7pPba"
      },
      "source": [
        "#### Configure the dataset for performance\n",
        "Let's make sure to use buffered prefetching so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data.\n",
        "\n",
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wZlKRBEGNtU"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "#### **Task 4: Create the model**\n",
        "Create a CNN model, which can accurately detect 9 classes present in the dataset. \n",
        "\n",
        "\n",
        "*   Note: The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`. Use `layers.experimental.preprocessing.Rescaling` for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ync9xoW7GZgn"
      },
      "source": [
        "### Your code goes here\n",
        "model = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h9Jp9mqEO4I"
      },
      "source": [
        "#### **Question**: \n",
        "Explain the following elements associated with the problem:\n",
        "1.   Selection of stride value (Reason for using a high/low value)\n",
        "2.   Padding strategy used (Same/Valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdx5gALTFBjo"
      },
      "source": [
        "`< Double click on the cell to write your answer here.>`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "#### **Task 5: Compile the model**\n",
        "Choose an appropirate optimiser and loss function for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8wKtiPGe1j"
      },
      "source": [
        "### Choose an appropirate optimiser and loss function\n",
        "model.compile(optimizer = 'your_optimser',\n",
        "              loss = your_loss_function_goes_here,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZGWN4MZGhtJ"
      },
      "source": [
        "# View the summary of all layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "source": [
        "# The model needs to be trained for 20 epochs\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data = val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "#### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "source": [
        "# Graphs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPphJYuSZhK"
      },
      "source": [
        "#### **Question**:\n",
        "Write your findings after the model fit, see if there is an evidence of model overfit or underfit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRTPbJEn-pX"
      },
      "source": [
        "`< Double click on the cell to write your answer here.>`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_0FHbmBw1bD"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGo9EzEgxwO2"
      },
      "source": [
        "Overfitting generally occurs when there are a small number of training examples. [Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation) takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22hljAl6GykA"
      },
      "source": [
        "# After you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(img_height, \n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf_Jm-gLC5pW"
      },
      "source": [
        "Let's visualize what a few augmented examples look like by applying data augmentation to the same image several times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEjPWh8GG0C7"
      },
      "source": [
        "# Visualizing how the augmentation strategy works for one instance of training image.\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      },
      "source": [
        "#### **Task 6: Create, compile and train the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMlf4NSDa6_"
      },
      "source": [
        "Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3V4l-O9G3dM"
      },
      "source": [
        "## Your code goes here\n",
        "## You should also include dropouts to tackle with overfitting. (compulsory)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUWFp96UIAN"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7yTm8IG8zR"
      },
      "source": [
        "## Your code goes here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC-D_RWOURp6"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcPfkUASHBf9"
      },
      "source": [
        "# Note: Train your model for 20 epochs\n",
        "## Your code goes here\n",
        "\n",
        "history = ## your training code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      },
      "source": [
        "#### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjN_F4QxHIsh"
      },
      "source": [
        "# Graphs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      },
      "source": [
        "#### **Question**:\n",
        "Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMlN9QD8Fndg"
      },
      "source": [
        "`< Double click on the cell to write your answer here.>`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Z8T-bfHMhj"
      },
      "source": [
        "## Distribution in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      },
      "source": [
        "**Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### **Task 7: Find the distribution of classes in the training dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhwYgtTQRzq"
      },
      "source": [
        "## Your code goes here.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csQL1dvO0b2"
      },
      "source": [
        "#### **Questions:**  \n",
        " - Which class has the least number of samples?\n",
        " - Which classes dominate the data in terms proportionate number of samples?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjntGiR2JcSw"
      },
      "source": [
        "`< Double click on the cell to write your answer here.>`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      },
      "source": [
        "#### **Task 8: Rectifying the class imbalance**\n",
        "You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItAg4rU-SzJh"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      },
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipelineâ€™s` `sample()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Egt9EHjR-Dd"
      },
      "source": [
        "# Provide the path for the training dataset\n",
        "path_to_training_dataset=\"Write the path here\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500)\n",
        "    ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jxWcMqZhdRWz"
      },
      "source": [
        "# Count of images under each class after addition\n",
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tODrYIY2nxJ"
      },
      "source": [
        "path_list = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "path_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvVdF7g3E1z"
      },
      "source": [
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
        "lesion_list_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "source": [
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njzBxTNT2nxK"
      },
      "source": [
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = original_df.append(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j45rmxd2nxK"
      },
      "source": [
        "new_df['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NirFBvGPmgI"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyVfE8zCMCip"
      },
      "source": [
        "### **Task 9: Repeating the steps for balanced augmented data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcj1XgndRWz"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0haOU11Ey8ey"
      },
      "source": [
        "**Create a training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ZY11judRWz"
      },
      "source": [
        "# Provide the path here\n",
        "data_dir_train=\"path to directory with training data + data created using augmentor\"\n",
        "\n",
        "# Provide the subset value here\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = ## Choose the correct parameter value, so that only training data is refered to,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      },
      "source": [
        "**Create a validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX191d_3dRW0"
      },
      "source": [
        "# Provide the subset value here\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = ## Choose the correct parameter value, so that only validation data is refered to,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      },
      "source": [
        "**Create your model (make sure to include normalization)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch0MuKvFVr7O"
      },
      "source": [
        "## Your code goes here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      },
      "source": [
        "**Compile your model (Choose optimizer and loss function appropriately)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47GWmLbdRW1"
      },
      "source": [
        "## Your code goes here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      },
      "source": [
        "**Train your model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcV6OdI4dRW1"
      },
      "source": [
        "# Note: Train your model for 30 epochs\n",
        "## Your code goes here\n",
        "\n",
        "history = # Code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      },
      "source": [
        "**Visualize the model results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCTXwfkTdRW1"
      },
      "source": [
        "# Graphs\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way4lakC4_p0"
      },
      "source": [
        "### **Task 10: Analyzing the results** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn7YlVt2NAQN"
      },
      "source": [
        "#### **Question:**\n",
        "- Did you get rid of underfitting/overfitting from the model? \n",
        "- Did class rebalance help in the process?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cLj3p1TNAWk"
      },
      "source": [
        "`< Double click on the cell to write your answer here.>`"
      ]
    }
  ]
}